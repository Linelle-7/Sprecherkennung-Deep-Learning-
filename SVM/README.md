ğŸ¤ Sprechererkennung mit SVM

ğŸ“Œ Projektbeschreibung

Dieses Projekt ermÃ¶glicht die automatische Sprechererkennung in Audiodateien und Live. Dabei werden Mel-Frequency Cepstral Coefficients (MFCCs) extrahiert und mit einer Support Vector Machine (SVM) klassifiziert. ZusÃ¤tzlich kÃ¶nnen die Hyperparameter mit Optuna & RandomizedSearchCV optimiert werden. Eine Gantt-Chart-Visualisierung zeigt die Sprecherwechsel grafisch an.

ğŸ› ï¸ Verwendete Technologien

Python (3.x)

Librosa (Audioanalyse)

Matplotlib & Seaborn (Visualisierungen)

Scikit-learn (Maschinelles Lernen)

Optuna (Hyperparameter-Optimierung)

Joblib (Parallele Verarbeitung)

Sounddevice (Live-Audio-Erkennung)

HMMlearn (Hidden Markov Models)

ğŸ“‚ Projektstruktur

ğŸ“ projektordner
â”‚-- ğŸ“„ main.py                   # Hauptskript zur AusfÃ¼hrung
â”‚-- ğŸ“„ speaker_recognition.py     # Funktionen zur Feature-Extraktion & Modelltraining
â”‚-- ğŸ“„ live_audio_analysis.py     # Live-Sprechererkennung
â”‚-- ğŸ“„ visualization.py           # Gantt-Chart & Confusion Matrix
â”‚-- ğŸ“‚ audio/                    # EnthÃ¤lt Audiodateien
â”‚-- ğŸ“‚ models/                   # Trainierte SVM-Modelle
â”‚-- ğŸ“„ README.md                 # Diese Datei

ğŸš€ Installation & AusfÃ¼hrung

1ï¸âƒ£ Voraussetzungen installieren

pip install librosa matplotlib numpy pandas scikit-learn optuna joblib sounddevice hmmlearn seaborn

2ï¸âƒ£ Skript ausfÃ¼hren

main teil

ğŸ¨ Hauptfunktionen

1. Feature-Extraktion (MFCCs)

Extrahiert Mel-Frequency Cepstral Coefficients aus Audiodateien.

UnterstÃ¼tzt Segmentierung zur feineren Analyse.

2. Modelltraining mit SVM & Hyperparameter-Tuning

RandomizedSearchCV fÃ¼r eine schnelle Optimierung(ist aber nur fÃ¼r kleine  Datenmenge geeignet daher werden ihre besten parameter als anfangsparameter fÃ¼r Optuna angewendet).

Optuna fÃ¼r eine tiefgehende Hyperparameter-Suche.

3. Sprecheridentifikation aus Audiodateien

Mithilfe des trainiertes Modells, einen gegebenen audio datei segmentiren und in jedes segment der Sprecher erkennen und die teilstÃ¼cken speichern.

Ergebnis kann in einem textdatei gespeichert und als Gantt-Chart visualisiert werden.

4. Live-Sprechererkennung (Mikrofon-Input)

Echtzeit-Speaker-Klassifikation mit gleitendem Durchschnitt (Moving Average).

ğŸ“Š Ausgabebeispiel einen Gantt-Diagramm

|------ Sprecher A ------|
            |---- Sprecher B ----|  
                                 |---- Sprecher C ---|

ğŸ† Metriken zur Bewertung

Confusion Matrix zur Analyse der Vorhersagen.

Accuracy, Precision, Recall, F1-Score zur Modellbewertung.

ğŸ“¬ Kontakt

Bei Fragen oder VorschlÃ¤gen gerne melden! ğŸ˜Š
